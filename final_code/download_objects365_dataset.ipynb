{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emSMHqK0WC8E",
    "outputId": "55a6d8aa-4757-4b09-c906-d0b5c3270227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 14 00:55:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H200 NVL                On  |   00000001:E1:00.0 Off |                    0 |\n",
      "| N/A   24C    P0             67W /  600W |       0MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1A\u001b[2K\u001b[1G\u001b[2K2025/11/14 01:05:20 ERROR : Google drive root '1LQ7IWDx1Ko5VAV9iOWw-iEUbJVv3rPxd': error reading source root directory: directory not found\n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Checks:                 0 / 0, -, Listed 7\n",
      "Elapsed time:         0.2s\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1G\u001b[2K2025/11/14 01:05:20 ERROR : Attempt 1/3 failed with 1 errors and: directory not found\n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Errors:                 1 (retrying may help)\n",
      "Checks:                 0 / 0, -, Listed 7\n",
      "Elapsed time:         0.2s\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1G\u001b[2K2025/11/14 01:05:21 ERROR : Google drive root '1LQ7IWDx1Ko5VAV9iOWw-iEUbJVv3rPxd': error reading source root directory: directory not found\n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Checks:                 0 / 0, -, Listed 14\n",
      "Elapsed time:         0.4s\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1G\u001b[2K2025/11/14 01:05:21 ERROR : Attempt 2/3 failed with 1 errors and: directory not found\n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Errors:                 1 (retrying may help)\n",
      "Checks:                 0 / 0, -, Listed 14\n",
      "Elapsed time:         0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Checks:                 0 / 0, -, Listed 21\n",
      "Elapsed time:         0.5s\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1G\u001b[2K2025/11/14 01:05:21 ERROR : Google drive root '1LQ7IWDx1Ko5VAV9iOWw-iEUbJVv3rPxd': error reading source root directory: directory not found\n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Checks:                 0 / 0, -, Listed 21\n",
      "Elapsed time:         0.5s\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1G\u001b[2K2025/11/14 01:05:21 ERROR : Attempt 3/3 failed with 1 errors and: directory not found\n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Errors:                 1 (retrying may help)\n",
      "Checks:                 0 / 0, -, Listed 21\n",
      "Elapsed time:         0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Errors:                 1 (retrying may help)\n",
      "Checks:                 0 / 0, -, Listed 21\n",
      "Elapsed time:         0.5s\n",
      "2025/11/14 01:05:21 NOTICE: Failed to copy: directory not found\n"
     ]
    }
   ],
   "source": [
    "!rclone copy \"goolge:O365_vehicle13_subset_2.zip\" \"/workspace\" \\\n",
    "    --progress \\\n",
    "    --drive-chunk-size 128M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "p7zip-full is already the newest version (16.02+transitional.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 74 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# 1. Installs the 7-Zip tool (which is multi-threaded)\n",
    "!apt-get install -y p7zip-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip 23.01 (x64) : Copyright (c) 1999-2023 Igor Pavlov : 2023-06-20\n",
      " 64-bit locale=C.UTF-8 Threads:512 OPEN_MAX:1048576\n",
      "\n",
      "Scanning the drive for archives:\n",
      "1 file, 126208459151 bytes (118 GiB)\n",
      "\n",
      "Extracting archive: /workspace/O365_vehicle13_subset_2.zip\n",
      "--\n",
      "Path = /workspace/O365_vehicle13_subset_2.zip\n",
      "Type = zip\n",
      "Physical Size = 126208459151\n",
      "64-bit = +\n",
      "Characteristics = Zip64\n",
      "\n",
      "Everything is Ok\n",
      "\n",
      "Folders: 196\n",
      "Files: 203895\n",
      "Size:       194211630267\n",
      "Compressed: 126208459151\n"
     ]
    }
   ],
   "source": [
    "# 2. Extract using 7z. This will use multiple CPU cores.\n",
    "# (x = extract, -o = output directory, no space)\n",
    "!7z x /workspace/O365_vehicle13_subset_2.zip -o /workspace/O365_vehicle13_subset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting path update in /workspace/O365_vehicle13_subset_2 ---\n",
      "[UPDATED] File: /workspace/O365_vehicle13_subset_2/o365_vehicle13_subset.yaml\n",
      "[UPDATED] File: /workspace/O365_vehicle13_subset_2/train_images.txt\n",
      "[UPDATED] File: /workspace/O365_vehicle13_subset_2/val_images.txt\n",
      "--- Update process finished. ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1. Define your paths and strings ---\n",
    "\n",
    "# The base directory where your files are located\n",
    "base_dir = Path(\"/workspace/O365_vehicle13_subset_2\")\n",
    "\n",
    "# The list of files to check and update\n",
    "files_to_update = [\n",
    "    \"o365_vehicle13_subset.yaml\",\n",
    "    \"train_images.txt\",\n",
    "    \"val_images.txt\"\n",
    "]\n",
    "\n",
    "# The string you want to find (your old Windows path)\n",
    "string_to_find = \"F:/ultralytics_datasets/O365_vehicle13_subset_2\"\n",
    "\n",
    "# The string you want to replace it with (your new Linux path)\n",
    "string_to_replace = \"/workspace/O365_vehicle13_subset_2\"\n",
    "\n",
    "print(f\"--- Starting path update in {base_dir} ---\")\n",
    "\n",
    "# --- 2. Loop through each file and perform the replacement ---\n",
    "\n",
    "for filename in files_to_update:\n",
    "    file_path = base_dir / filename\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"[NOT FOUND] File: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Read the file content\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # Perform the replacement\n",
    "        if string_to_find in content:\n",
    "            new_content = content.replace(string_to_find, string_to_replace)\n",
    "            \n",
    "            # Write the new content back to the file\n",
    "            with open(file_path, 'w') as f:\n",
    "                f.write(new_content)\n",
    "                \n",
    "            print(f\"[UPDATED] File: {file_path}\")\n",
    "        else:\n",
    "            print(f\"[NO CHANGE] File: {file_path} (string not found)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not process {file_path}: {e}\")\n",
    "\n",
    "print(\"--- Update process finished. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5t7B1cmWIvq",
    "outputId": "36c22761-f2d7-45d4-b244-6d84bc7b835b"
   },
   "outputs": [],
   "source": [
    "!pip -q install -U ultralytics pycocotools tqdm rich\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Point Ultralytics \"datasets\" and \"runs\" to Drive\n",
    "from ultralytics import settings\n",
    "DATASETS_DIR = \"/content/drive/MyDrive/ultralytics_datasets\"\n",
    "RUNS_DIR     = \"/content/drive/MyDrive/ultralytics_runs\"\n",
    "settings.update({\"datasets_dir\": DATASETS_DIR, \"runs_dir\": RUNS_DIR})\n",
    "print(\"Ultralytics datasets_dir:\", settings[\"datasets_dir\"])\n",
    "print(\"Ultralytics runs_dir    :\", settings[\"runs_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8NN469MXDes"
   },
   "outputs": [],
   "source": [
    "# High-performance tools for parallel download/extraction\n",
    "!apt -yqq update\n",
    "!apt -yqq install aria2 p7zip-full pigz parallel > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2zDMHLqXLFj",
    "outputId": "13578335-47ff-4925-8062-04a99e69fb62"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Where to place Objects365 on your Drive\n",
    "DRIVE_O365 = Path(\"/content/drive/MyDrive/ultralytics_datasets/Objects365\")\n",
    "ZIPS_DIR   = DRIVE_O365/\"zips\"\n",
    "TRAIN_ZIPS = ZIPS_DIR/\"train\"\n",
    "VAL_ZIPS   = ZIPS_DIR/\"val\"\n",
    "IM_TRAIN   = DRIVE_O365/\"images/train\"\n",
    "IM_VAL     = DRIVE_O365/\"images/val\"\n",
    "\n",
    "# Create folders\n",
    "for p in [TRAIN_ZIPS, VAL_ZIPS, IM_TRAIN, IM_VAL]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Dataset root:\", DRIVE_O365)\n",
    "\n",
    "# ---- Concurrency knobs ----\n",
    "# aria2c: connections per server, splits per file, simultaneous files\n",
    "A2C_X = 16   # -x\n",
    "A2C_S = 16   # -s\n",
    "A2C_J = 16   # -j\n",
    "\n",
    "# Extraction parallelism (how many tar extractions to run at once)\n",
    "EXTRACT_J = 6  # try 6-8 on Pro; tune for IO speed\n",
    "\n",
    "print(f\"aria2c: -x{A2C_X} -s{A2C_S} -j{A2C_J} | extraction parallel -j {EXTRACT_J}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ontXUExZXOzb",
    "outputId": "f2796633-6943-4439-e898-8df73e518222"
   },
   "outputs": [],
   "source": [
    "# Base URL (exactly as in YAML; URL-encoded Chinese chars kept)\n",
    "BASE = \"https://dorc.ks3-cn-beijing.ksyun.com/data-set/2020Objects365%E6%95%B0%E6%8D%AE%E9%9B%86\"\n",
    "\n",
    "train_ann_url = f\"{BASE}/train/zhiyuan_objv2_train.tar.gz\"\n",
    "train_patch_urls = [f\"{BASE}/train/patch{i}.tar.gz\" for i in range(0, 51)]  # 0..50 inclusive\n",
    "\n",
    "val_ann_url = f\"{BASE}/val/zhiyuan_objv2_val.json\"\n",
    "val_v1_urls = [f\"{BASE}/val/images/v1/patch{i}.tar.gz\" for i in range(0, 16)]  # 0..15\n",
    "val_v2_urls = [f\"{BASE}/val/images/v2/patch{i}.tar.gz\" for i in range(16, 44)] # 16..43\n",
    "\n",
    "len(train_patch_urls), len(val_v1_urls), len(val_v2_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEoEHtv6XS6v",
    "outputId": "6b8f7844-ddde-43ea-9d98-b4f81b2338d0"
   },
   "outputs": [],
   "source": [
    "# Write URL lists to text files\n",
    "(TRAIN_ZIPS/\"train_patches.txt\").write_text(\"\\n\".join(train_patch_urls))\n",
    "(VAL_ZIPS/\"val_patches.txt\").write_text(\"\\n\".join(val_v1_urls + val_v2_urls))\n",
    "\n",
    "print(\"Downloading TRAIN annotations (tar.gz) ->\", DRIVE_O365)\n",
    "!aria2c -x{A2C_X} -s{A2C_S} -j{A2C_J} -c -k1M \"{train_ann_url}\" -d \"{DRIVE_O365}\" -o \"zhiyuan_objv2_train.tar.gz\"\n",
    "\n",
    "print(\"Downloading TRAIN image patches ->\", TRAIN_ZIPS)\n",
    "!aria2c -x{A2C_X} -s{A2C_S} -j{A2C_J} -c -k1M -i \"{TRAIN_ZIPS}/train_patches.txt\" -d \"{TRAIN_ZIPS}\"\n",
    "\n",
    "print(\"Downloading VAL annotations (json) ->\", DRIVE_O365)\n",
    "!aria2c -x{A2C_X} -s{A2C_S} -j{A2C_J} -c -k1M \"{val_ann_url}\" -d \"{DRIVE_O365}\" -o \"zhiyuan_objv2_val.json\"\n",
    "\n",
    "print(\"Downloading VAL image patches ->\", VAL_ZIPS)\n",
    "!aria2c -x{A2C_X} -s{A2C_S} -j{A2C_J} -c -k1M -i \"{VAL_ZIPS}/val_patches.txt\" -d \"{VAL_ZIPS}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTXnffQCNI1a",
    "outputId": "9e7a9d82-d7ca-4e42-a255-98658308a402"
   },
   "outputs": [],
   "source": [
    "# Same paths you used before\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_O365 = Path(\"/content/drive/MyDrive/ultralytics_datasets/Objects365\")\n",
    "TRAIN_ZIPS = DRIVE_O365 / \"zips/train\"\n",
    "VAL_ZIPS   = DRIVE_O365 / \"zips/val\"\n",
    "IM_TRAIN   = DRIVE_O365 / \"images/train\"\n",
    "IM_VAL     = DRIVE_O365 / \"images/val\"\n",
    "\n",
    "IM_TRAIN.mkdir(parents=True, exist_ok=True)\n",
    "IM_VAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"TRAIN_ZIPS:\", TRAIN_ZIPS)\n",
    "print(\"VAL_ZIPS  :\", VAL_ZIPS)\n",
    "print(\"IM_TRAIN  :\", IM_TRAIN)\n",
    "print(\"IM_VAL    :\", IM_VAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YL1fnO0wMsTJ",
    "outputId": "4d4f8ab0-6578-44fc-d67b-5a7f88bcaea5"
   },
   "outputs": [],
   "source": [
    "import concurrent.futures, subprocess, glob, os, re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- helpers for parsing and selection ---\n",
    "\n",
    "def _tar_basename(p: str) -> str:\n",
    "    \"\"\"Return filename without .tar.gz/.tgz.\"\"\"\n",
    "    name = os.path.basename(p)\n",
    "    if name.endswith(\".tar.gz\"):\n",
    "        return name[:-7]\n",
    "    if name.endswith(\".tgz\"):\n",
    "        return name[:-4]\n",
    "    # Fallback\n",
    "    return os.path.splitext(name)[0]\n",
    "\n",
    "def _extract_index_from_name(name: str):\n",
    "    \"\"\"Use the LAST run of digits in the basename as the patch index (e.g., 'patch10' -> 10).\"\"\"\n",
    "    m = re.search(r'(\\d+)(?!.*\\d)', _tar_basename(name))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def _select_from_index_lexicographic(files, start_index: int):\n",
    "    \"\"\"\n",
    "    Keep lexicographic order (by filename) and return the slice starting from\n",
    "    the first file whose parsed index == start_index. If not found, return all\n",
    "    files whose parsed index >= start_index (still in lexicographic order).\n",
    "    \"\"\"\n",
    "    files_sorted = sorted(files, key=lambda x: os.path.basename(x))\n",
    "    pivot = None\n",
    "    for i, f in enumerate(files_sorted):\n",
    "        idx = _extract_index_from_name(f)\n",
    "        if idx == start_index:\n",
    "            pivot = i\n",
    "            break\n",
    "    if pivot is not None:\n",
    "        selected = files_sorted[pivot:]\n",
    "    else:\n",
    "        selected = [f for f in files_sorted if (_extract_index_from_name(f) or -1) >= start_index]\n",
    "    return selected\n",
    "\n",
    "# --- your original extraction helpers ---\n",
    "\n",
    "def extract_with_tar_skip(tar_path: str, dest_dir: str):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    cmd = [\"tar\", \"--skip-old-files\", \"-xzf\", tar_path, \"-C\", dest_dir]\n",
    "    # If GNU tar doesn't support --skip-old-files on your system, fall back:\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    except subprocess.CalledProcessError:\n",
    "        subprocess.run([\"tar\", \"--keep-old-files\", \"-xzf\", tar_path, \"-C\", dest_dir],\n",
    "                       check=False, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "\n",
    "def extract_batch(pattern: str, dest_dir: str, workers: int = 1, desc: str = \"\", start_index: int = None):\n",
    "    all_files = sorted(glob.glob(pattern), key=lambda x: os.path.basename(x))\n",
    "    if not all_files:\n",
    "        print(f\"⚠️ No archives matched: {pattern}\")\n",
    "        return\n",
    "\n",
    "    if start_index is not None:\n",
    "        files = _select_from_index_lexicographic(all_files, start_index)\n",
    "        if not files:\n",
    "            print(f\"⚠️ No files at or beyond start index {start_index} under pattern: {pattern}\")\n",
    "            return\n",
    "        # Diagnostics (optional)\n",
    "        print(f\"Selected {len(files)} / {len(all_files)} files starting from index {start_index}\")\n",
    "        print(\"First few to extract:\", \", \".join(os.path.basename(f) for f in files[:5]))\n",
    "    else:\n",
    "        files = all_files\n",
    "\n",
    "    pbar = tqdm(total=len(files), desc=desc or f\"Extract → {dest_dir}\", unit=\"tar\")\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as ex:\n",
    "        futures = [ex.submit(extract_with_tar_skip, f, dest_dir) for f in files]\n",
    "        for _ in concurrent.futures.as_completed(futures):\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "# ----------------- USAGE -----------------\n",
    "# Assumes TRAIN_ZIPS, VAL_ZIPS, IM_TRAIN, IM_VAL are defined elsewhere\n",
    "# Start TRAIN from '29' onward in *lexicographic* order, process all VAL\n",
    "# extract_batch(str(Path(TRAIN_ZIPS) / \"*.tar.gz\"), str(IM_TRAIN),\n",
    "#               workers=4, desc=\"TRAIN extract (29+; idempotent)\", start_index=43)\n",
    "\n",
    "extract_batch(str(Path(VAL_ZIPS) / \"*.tar.gz\"),   str(IM_VAL),\n",
    "              workers=4, desc=\"VAL extract (all; idempotent)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzuA-Ij7FBTp",
    "outputId": "3aef8966-ab08-4883-a033-58f1b0ed3150"
   },
   "outputs": [],
   "source": [
    "!find /content/drive/MyDrive/ultralytics_datasets/Objects365/images/train/patch43 -maxdepth 1 -type f | wc -l\n",
    "!du -sh /content/drive/MyDrive/ultralytics_datasets/Objects365/images/train/patch43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGlhmLdJIKqP",
    "outputId": "bef55ae3-8b78-43cb-ad62-bb2d0250d0fe"
   },
   "outputs": [],
   "source": [
    "!gzip -cd /content/drive/MyDrive/ultralytics_datasets/Objects365/zips/train/patch0.tar.gz | tar -tvv | grep -c ^-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DElFcZZAJzGr",
    "outputId": "f04e3c30-1dd0-41ab-9015-2527508efb52"
   },
   "outputs": [],
   "source": [
    "!ls /content/drive/MyDrive/ultralytics_datasets/Objects365/images/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Kg5eL_4SECSR",
    "outputId": "080bf01d-0a34-407b-c9b0-b0b51c969104"
   },
   "outputs": [],
   "source": [
    "# === Objects365 extraction integrity check (follows notebook paths) ===\n",
    "from pathlib import Path\n",
    "import os, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths exactly as defined in your .ipynb\n",
    "DRIVE_O365 = Path(\"/content/drive/MyDrive/ultralytics_datasets/Objects365\")\n",
    "ZIPS_DIR   = DRIVE_O365 / \"zips\"\n",
    "TRAIN_ZIPS = ZIPS_DIR / \"train\"\n",
    "VAL_ZIPS   = ZIPS_DIR / \"val\"\n",
    "IM_TRAIN   = DRIVE_O365 / \"images\" / \"train\"\n",
    "IM_VAL     = DRIVE_O365 / \"images\" / \"val\"\n",
    "\n",
    "def get_size(path: Path) -> int:\n",
    "    \"\"\"Total size (bytes) for a file or a directory (recursive). Missing -> 0.\"\"\"\n",
    "    if not path.exists():\n",
    "        return 0\n",
    "    if path.is_file():\n",
    "        return path.stat().st_size\n",
    "    total = 0\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            fp = Path(root) / f\n",
    "            try:\n",
    "                total += fp.stat().st_size\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "    return total\n",
    "\n",
    "def compare_split(split_name: str, tar_dir: Path, img_dir: Path):\n",
    "    rows = []\n",
    "    if not tar_dir.exists():\n",
    "        print(f\"[{split_name}] tar dir does not exist: {tar_dir}\")\n",
    "        return rows\n",
    "    tar_files = sorted(tar_dir.glob(\"*.tar.gz\"))\n",
    "    print(f\"[{split_name}] Found {len(tar_files)} tar.gz\")\n",
    "    for tar_path in tar_files:\n",
    "        patch_name  = tar_path.stem.replace(\".tar\", \"\")  # e.g., 'patch123'\n",
    "        patch_dir   = img_dir / patch_name               # assumes same top-level folder inside tar\n",
    "        tar_bytes   = get_size(tar_path)\n",
    "        fold_bytes  = get_size(patch_dir)\n",
    "        ratio       = (fold_bytes / tar_bytes) if tar_bytes else 0.0\n",
    "        status      = \"OK\" if (fold_bytes > tar_bytes) else \"SMALLER_OR_MISSING\"\n",
    "        rows.append(dict(\n",
    "            split=split_name,\n",
    "            patch=patch_name,\n",
    "            tar_path=str(tar_path),\n",
    "            patch_folder=str(patch_dir),\n",
    "            tar_size_bytes=tar_bytes,\n",
    "            folder_size_bytes=fold_bytes,\n",
    "            ratio_folder_to_tar=ratio,\n",
    "            status=status\n",
    "        ))\n",
    "    return rows\n",
    "\n",
    "all_rows = []\n",
    "all_rows += compare_split(\"train\", TRAIN_ZIPS, IM_TRAIN)\n",
    "all_rows += compare_split(\"val\",   VAL_ZIPS,   IM_VAL)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "if not df.empty:\n",
    "    df = df.sort_values([\"split\",\"patch\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "if df.empty:\n",
    "    print(\"No tarballs found under notebook paths. Check that Drive is mounted and zips are present.\")\n",
    "else:\n",
    "    # Pretty print a compact table\n",
    "    display(df[[\"split\",\"patch\",\"tar_size_bytes\",\"folder_size_bytes\",\"ratio_folder_to_tar\",\"status\"]].head(30))\n",
    "    flagged = df[df[\"status\"] == \"SMALLER_OR_MISSING\"]\n",
    "    print(f\"Flagged patches: {len(flagged)} / {len(df)}\")\n",
    "    if not flagged.empty:\n",
    "        display(flagged[[\"split\",\"patch\",\"tar_path\",\"patch_folder\",\"tar_size_bytes\",\"folder_size_bytes\",\"ratio_folder_to_tar\"]])\n",
    "\n",
    "# Save CSV report next to the notebook (in /content by default) or in Drive; here we put it in Drive\n",
    "reports_dir = DRIVE_O365 / \"reports\"\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_csv = reports_dir / f\"objects365_extraction_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "(df if not df.empty else pd.DataFrame(columns=[\n",
    "    \"split\",\"patch\",\"tar_path\",\"patch_folder\",\"tar_size_bytes\",\"folder_size_bytes\",\"ratio_folder_to_tar\",\"status\"\n",
    "])).to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved report to: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8e1fRoMsUdE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzJKwugz4q5W",
    "outputId": "e5faaca7-f46a-4bf5-8daa-d4b00b1fe852"
   },
   "outputs": [],
   "source": [
    "!pip -q install -U ultralytics pycocotools tqdm\n",
    "\n",
    "from ultralytics import settings\n",
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Put datasets and runs on Drive\n",
    "DATASETS_DIR = \"/content/drive/MyDrive/ultralytics_datasets\"\n",
    "RUNS_DIR     = \"/content/drive/MyDrive/ultralytics_runs\"\n",
    "settings.update({\"datasets_dir\": DATASETS_DIR, \"runs_dir\": RUNS_DIR})\n",
    "print(\"datasets_dir:\", settings[\"datasets_dir\"])\n",
    "print(\"runs_dir    :\", settings[\"runs_dir\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSz1twWP4rof",
    "outputId": "5402797d-654f-45f2-a719-4cd42198fc92"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- Root of your Objects365 on Drive (matches your screenshot) ---\n",
    "DRIVE_O365 = Path(\"/content/drive/MyDrive/ultralytics_datasets/Objects365\")\n",
    "\n",
    "# Images and labels dirs\n",
    "IM_TRAIN = DRIVE_O365 / \"images/train\"\n",
    "IM_VAL   = DRIVE_O365 / \"images/val\"\n",
    "LB_TRAIN = DRIVE_O365 / \"labels/train\"\n",
    "LB_VAL   = DRIVE_O365 / \"labels/val\"\n",
    "\n",
    "# Make sure label dirs exist (images should already exist after extraction)\n",
    "LB_TRAIN.mkdir(parents=True, exist_ok=True)\n",
    "LB_VAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Images train:\", IM_TRAIN)\n",
    "print(\"Images val  :\", IM_VAL)\n",
    "print(\"Labels train:\", LB_TRAIN)\n",
    "print(\"Labels val  :\", LB_VAL)\n",
    "\n",
    "# --- Annotations live at the ROOT (explicit paths) ---\n",
    "TRAIN_JSON = DRIVE_O365 / \"zhiyuan_objv2_train.json\"\n",
    "VAL_JSON   = DRIVE_O365 / \"zhiyuan_objv2_val.json\"\n",
    "\n",
    "# Sanity checks\n",
    "assert IM_TRAIN.exists(), f\"Missing images/train: {IM_TRAIN}\"\n",
    "assert IM_VAL.exists(),   f\"Missing images/val:   {IM_VAL}\"\n",
    "assert TRAIN_JSON.exists(), f\"Missing train JSON at root: {TRAIN_JSON}\\nIf you only have 'zhiyuan_objv2_train.tar.gz', extract it to this folder.\"\n",
    "assert VAL_JSON.exists(),   f\"Missing val JSON at root:   {VAL_JSON}\"\n",
    "\n",
    "print(\"TRAIN_JSON:\", TRAIN_JSON)\n",
    "print(\"VAL_JSON  :\", VAL_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "v8ePdqzR4tU9",
    "outputId": "bd765abb-ef2e-49aa-d9a5-a0d49f907ab3"
   },
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Your requested classes (exact names from YAML list)\n",
    "TARGET_NAMES = [\n",
    "    \"Car\",\"SUV\",\"Bicycle\",\"Van\",\"Bus\",\"Motorcycle\",\"Truck\",\"Pickup Truck\",\n",
    "    \"Machinery Vehicle\",\"Sports Car\",\"Fire Truck\",\"Heavy Truck\",\"Ambulance\"\n",
    "]\n",
    "\n",
    "MIN_BOX_AREA_PX = 4 * 4  # filter tiny boxes\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", s.strip().lower())\n",
    "\n",
    "def load_coco(json_path: Path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        coco = json.load(f)\n",
    "    cats = {c[\"id\"]: c for c in coco[\"categories\"]}\n",
    "    imgs = {im[\"id\"]: im for im in coco[\"images\"]}\n",
    "    anns_by_img = defaultdict(list)\n",
    "    for a in coco[\"annotations\"]:\n",
    "        anns_by_img[a[\"image_id\"]].append(a)\n",
    "    # Build normalized name -> id map (handle minor case/spacing diffs)\n",
    "    name2id_norm = {norm(c[\"name\"]): cid for cid, c in cats.items()}\n",
    "    return cats, imgs, anns_by_img, name2id_norm\n",
    "\n",
    "def map_targets_to_ids(name2id_norm: dict, targets: list[str]):\n",
    "    resolved, missing = {}, []\n",
    "    for t in targets:\n",
    "        key = norm(t)\n",
    "        if key in name2id_norm:\n",
    "            resolved[t] = name2id_norm[key]\n",
    "        else:\n",
    "            # fuzzy: substring both ways\n",
    "            cand = None\n",
    "            for k, cid in name2id_norm.items():\n",
    "                if key in k or k in key:\n",
    "                    cand = cid; break\n",
    "            if cand is None:\n",
    "                missing.append(t)\n",
    "            else:\n",
    "                resolved[t] = cand\n",
    "    return resolved, missing\n",
    "\n",
    "def normalize_rel_path(file_name: str, split: str):\n",
    "    \"\"\"Make path relative to images/<split>/ for label mirroring.\"\"\"\n",
    "    p = Path(file_name).as_posix().lstrip(\"/\")\n",
    "    # Strip common prefixes if present\n",
    "    for prefix in [f\"images/{split}/\", f\"{split}/\", \"images/\"]:\n",
    "        if p.startswith(prefix):\n",
    "            p = p[len(prefix):]\n",
    "    return p\n",
    "\n",
    "def index_images(images_dir: Path):\n",
    "    \"\"\"Map: rel_path -> True, and basename -> [rel_paths] for fallback.\"\"\"\n",
    "    rel_exists = set()\n",
    "    by_base = defaultdict(list)\n",
    "    for root, _, files in os.walk(images_dir):\n",
    "        rroot = Path(root).relative_to(images_dir)\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
    "                rel = (Path(rroot)/fn).as_posix()\n",
    "                rel_exists.add(rel)\n",
    "                by_base[fn].append(rel)\n",
    "    return rel_exists, by_base\n",
    "\n",
    "def write_label(im, anns, labels_root: Path, catid2idx: dict, split: str, rel_path: str):\n",
    "    \"\"\"Write one YOLO .txt label, mirroring the image's rel path.\"\"\"\n",
    "    out_path = labels_root / Path(rel_path).with_suffix(\".txt\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    w, h = im[\"width\"], im[\"height\"]\n",
    "    lines = []\n",
    "    for a in anns:\n",
    "        cid = a[\"category_id\"]\n",
    "        if cid not in catid2idx:\n",
    "            continue\n",
    "        x, y, bw, bh = a[\"bbox\"]  # COCO xywh in pixels\n",
    "        if bw <= 0 or bh <= 0 or (bw*bh) < MIN_BOX_AREA_PX:\n",
    "            continue\n",
    "        xc = (x + bw/2.0) / w\n",
    "        yc = (y + bh/2.0) / h\n",
    "        ww = bw / w\n",
    "        hh = bh / h\n",
    "        # clip\n",
    "        xc = min(max(xc, 0.0), 1.0)\n",
    "        yc = min(max(yc, 0.0), 1.0)\n",
    "        ww = min(max(ww, 0.0), 1.0)\n",
    "        hh = min(max(hh, 0.0), 1.0)\n",
    "        lines.append(f\"{catid2idx[cid]} {xc:.6f} {yc:.6f} {ww:.6f} {hh:.6f}\")\n",
    "    if lines:\n",
    "        with open(out_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def convert_split(json_path: Path, images_dir: Path, labels_dir: Path, target_names: list[str], split: str):\n",
    "    cats, imgs, anns_by_img, name2id_norm = load_coco(json_path)\n",
    "    resolved, missing = map_targets_to_ids(name2id_norm, target_names)\n",
    "\n",
    "    print(f\"\\n[{json_path.name}] target mapping:\")\n",
    "    for t in target_names:\n",
    "        if t in resolved:\n",
    "            print(f\"  {t:18s} -> id {resolved[t]} ({cats[resolved[t]]['name']})\")\n",
    "        else:\n",
    "            print(f\"  {t:18s} -> NOT FOUND\")\n",
    "    if missing:\n",
    "        print(\"⚠️ Missing targets (check spelling/case):\", missing)\n",
    "\n",
    "    keep_cids = set(resolved.values())\n",
    "    catid2idx = {cid: i for i, cid in enumerate([resolved[t] for t in target_names if t in resolved])}\n",
    "    yolo_names = [cats[cid][\"name\"] for cid in [resolved[t] for t in target_names if t in resolved]]\n",
    "\n",
    "    # Build image indexes (existing rel paths + basename fallback)\n",
    "    rel_exists, by_base = index_images(images_dir)\n",
    "\n",
    "    # Select candidate image IDs that contain ≥1 of the target categories\n",
    "    candidates = []\n",
    "    for img_id, ann_list in anns_by_img.items():\n",
    "        if any(a[\"category_id\"] in keep_cids for a in ann_list):\n",
    "            candidates.append(img_id)\n",
    "    print(f\"[{split}] images with target classes in annotations: {len(candidates):,}\")\n",
    "\n",
    "    # Multithread label creation with robust rel-path resolution\n",
    "    used_rel_paths = []\n",
    "    ok = 0\n",
    "    def process(img_id):\n",
    "        im = imgs[img_id]\n",
    "        raw = im.get(\"file_name\") or im.get(\"filename\")\n",
    "        rel = normalize_rel_path(raw, split)\n",
    "        # If not found as-is, resolve by basename\n",
    "        rel_resolved = rel\n",
    "        if rel not in rel_exists:\n",
    "            base = Path(rel).name\n",
    "            cands = by_base.get(base, [])\n",
    "            if len(cands) == 1:\n",
    "                rel_resolved = cands[0]\n",
    "            elif len(cands) > 1:\n",
    "                # heuristic: pick the one whose parent contains a token from raw\n",
    "                parent_tokens = set(Path(raw).parts)\n",
    "                rel_resolved = next((c for c in cands if any(t in c for t in parent_tokens)), cands[0]) if cands else rel\n",
    "            else:\n",
    "                return False  # image file not on disk -> skip\n",
    "        ann_keep = [a for a in anns_by_img[img_id] if a[\"category_id\"] in keep_cids]\n",
    "        wrote = write_label(im, ann_keep, labels_dir, catid2idx, split, rel_resolved)\n",
    "        if wrote:\n",
    "            used_rel_paths.append(rel_resolved)\n",
    "        return wrote\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=16) as ex:\n",
    "        futures = [ex.submit(process, iid) for iid in candidates]\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=f\"Writing {split} labels\"):\n",
    "            ok += 1 if f.result() else 0\n",
    "\n",
    "    print(f\"Wrote {ok} label files to {labels_dir}\")\n",
    "    return yolo_names, used_rel_paths\n",
    "\n",
    "# Run for train/val\n",
    "names_train, used_train = convert_split(TRAIN_JSON, IM_TRAIN, LB_TRAIN, TARGET_NAMES, split=\"train\")\n",
    "names_val,   used_val   = convert_split(VAL_JSON,   IM_VAL,   LB_VAL,   TARGET_NAMES, split=\"val\")\n",
    "\n",
    "# Final names in YOUR requested order (from train mapping)\n",
    "YOLO_NAMES = names_train\n",
    "print(\"\\nYOLO class order (index -> name):\")\n",
    "for i, n in enumerate(YOLO_NAMES):\n",
    "    print(f\" {i:2d} -> {n}\")\n",
    "\n",
    "# Save image lists (absolute paths) so Ultralytics reads nested images reliably\n",
    "train_list = [str(IM_TRAIN / p) for p in used_train]\n",
    "val_list   = [str(IM_VAL   / p) for p in used_val]\n",
    "(Path(DRIVE_O365/\"train_images.txt\")).write_text(\"\\n\".join(train_list))\n",
    "(Path(DRIVE_O365/\"val_images.txt\")).write_text(\"\\n\".join(val_list))\n",
    "print(f\"Saved lists:\\n  {DRIVE_O365/'train_images.txt'}  ({len(train_list):,} lines)\\n  {DRIVE_O365/'val_images.txt'}    ({len(val_list):,} lines)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "Uzs1CJDANy1W",
    "outputId": "dcf1b6f0-382a-40ac-d0c3-36820e2563e1"
   },
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Your requested classes (exact names from YAML list)\n",
    "TARGET_NAMES = [\n",
    "    \"Car\",\"SUV\",\"Bicycle\",\"Van\",\"Bus\",\"Motorcycle\",\"Truck\",\"Pickup Truck\",\n",
    "    \"Machinery Vehicle\",\"Sports Car\",\"Fire Truck\",\"Heavy Truck\",\"Ambulance\"\n",
    "]\n",
    "\n",
    "MIN_BOX_AREA_PX = 4 * 4  # filter tiny boxes\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", s.strip().lower())\n",
    "\n",
    "def load_coco(json_path: Path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        coco = json.load(f)\n",
    "    cats = {c[\"id\"]: c for c in coco[\"categories\"]}\n",
    "    imgs = {im[\"id\"]: im for im in coco[\"images\"]}\n",
    "    anns_by_img = defaultdict(list)\n",
    "    for a in coco[\"annotations\"]:\n",
    "        anns_by_img[a[\"image_id\"]].append(a)\n",
    "    # Build normalized name -> id map (handle minor case/spacing diffs)\n",
    "    name2id_norm = {norm(c[\"name\"]): cid for cid, c in cats.items()}\n",
    "    return cats, imgs, anns_by_img, name2id_norm\n",
    "\n",
    "def map_targets_to_ids(name2id_norm: dict, targets: list[str]):\n",
    "    resolved, missing = {}, []\n",
    "    for t in targets:\n",
    "        key = norm(t)\n",
    "        if key in name2id_norm:\n",
    "            resolved[t] = name2id_norm[key]\n",
    "        else:\n",
    "            # fuzzy: substring both ways\n",
    "            cand = None\n",
    "            for k, cid in name2id_norm.items():\n",
    "                if key in k or k in key:\n",
    "                    cand = cid; break\n",
    "            if cand is None:\n",
    "                missing.append(t)\n",
    "            else:\n",
    "                resolved[t] = cand\n",
    "    return resolved, missing\n",
    "\n",
    "def normalize_rel_path(file_name: str, split: str):\n",
    "    \"\"\"Make path relative to images/<split>/ for label mirroring.\"\"\"\n",
    "    p = Path(file_name).as_posix().lstrip(\"/\")\n",
    "    # Strip common prefixes if present\n",
    "    for prefix in [f\"images/{split}/\", f\"{split}/\", \"images/\"]:\n",
    "        if p.startswith(prefix):\n",
    "            p = p[len(prefix):]\n",
    "    return p\n",
    "\n",
    "def index_images(images_dir: Path):\n",
    "    \"\"\"Map: rel_path -> True, and basename -> [rel_paths] for fallback.\"\"\"\n",
    "    rel_exists = set()\n",
    "    by_base = defaultdict(list)\n",
    "    for root, _, files in os.walk(images_dir):\n",
    "        rroot = Path(root).relative_to(images_dir)\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
    "                rel = (Path(rroot)/fn).as_posix()\n",
    "                rel_exists.add(rel)\n",
    "                by_base[fn].append(rel)\n",
    "    return rel_exists, by_base\n",
    "\n",
    "def write_label(im, anns, labels_root: Path, catid2idx: dict, split: str, rel_path: str):\n",
    "    \"\"\"Write one YOLO .txt label, mirroring the image's rel path.\"\"\"\n",
    "    out_path = labels_root / Path(rel_path).with_suffix(\".txt\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    w, h = im[\"width\"], im[\"height\"]\n",
    "    lines = []\n",
    "    for a in anns:\n",
    "        cid = a[\"category_id\"]\n",
    "        if cid not in catid2idx:\n",
    "            continue\n",
    "        x, y, bw, bh = a[\"bbox\"]  # COCO xywh in pixels\n",
    "        if bw <= 0 or bh <= 0 or (bw*bh) < MIN_BOX_AREA_PX:\n",
    "            continue\n",
    "        xc = (x + bw/2.0) / w\n",
    "        yc = (y + bh/2.0) / h\n",
    "        ww = bw / w\n",
    "        hh = bh / h\n",
    "        # clip\n",
    "        xc = min(max(xc, 0.0), 1.0)\n",
    "        yc = min(max(yc, 0.0), 1.0)\n",
    "        ww = min(max(ww, 0.0), 1.0)\n",
    "        hh = min(max(hh, 0.0), 1.0)\n",
    "        lines.append(f\"{catid2idx[cid]} {xc:.6f} {yc:.6f} {ww:.6f} {hh:.6f}\")\n",
    "    if lines:\n",
    "        with open(out_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def convert_split(json_path: Path, images_dir: Path, labels_dir: Path, target_names: list[str], split: str):\n",
    "    cats, imgs, anns_by_img, name2id_norm = load_coco(json_path)\n",
    "    resolved, missing = map_targets_to_ids(name2id_norm, target_names)\n",
    "\n",
    "    print(f\"\\n[{json_path.name}] target mapping:\")\n",
    "    for t in target_names:\n",
    "        if t in resolved:\n",
    "            print(f\"  {t:18s} -> id {resolved[t]} ({cats[resolved[t]]['name']})\")\n",
    "        else:\n",
    "            print(f\"  {t:18s} -> NOT FOUND\")\n",
    "    if missing:\n",
    "        print(\"⚠️ Missing targets (check spelling/case):\", missing)\n",
    "\n",
    "    keep_cids = set(resolved.values())\n",
    "    catid2idx = {cid: i for i, cid in enumerate([resolved[t] for t in target_names if t in resolved])}\n",
    "    yolo_names = [cats[cid][\"name\"] for cid in [resolved[t] for t in target_names if t in resolved]]\n",
    "\n",
    "    # Build image indexes (existing rel paths + basename fallback)\n",
    "    rel_exists, by_base = index_images(images_dir)\n",
    "\n",
    "    # Select candidate image IDs that contain ≥1 of the target categories\n",
    "    candidates = []\n",
    "    for img_id, ann_list in anns_by_img.items():\n",
    "        if any(a[\"category_id\"] in keep_cids for a in ann_list):\n",
    "            candidates.append(img_id)\n",
    "    print(f\"[{split}] images with target classes in annotations: {len(candidates):,}\")\n",
    "\n",
    "    # Multithread label creation with robust rel-path resolution\n",
    "    used_rel_paths = []\n",
    "    ok = 0\n",
    "    def process(img_id):\n",
    "        im = imgs[img_id]\n",
    "        raw = im.get(\"file_name\") or im.get(\"filename\")\n",
    "        rel = normalize_rel_path(raw, split)\n",
    "        # If not found as-is, resolve by basename\n",
    "        rel_resolved = rel\n",
    "        if rel not in rel_exists:\n",
    "            base = Path(rel).name\n",
    "            cands = by_base.get(base, [])\n",
    "            if len(cands) == 1:\n",
    "                rel_resolved = cands[0]\n",
    "            elif len(cands) > 1:\n",
    "                # heuristic: pick the one whose parent contains a token from raw\n",
    "                parent_tokens = set(Path(raw).parts)\n",
    "                rel_resolved = next((c for c in cands if any(t in c for t in parent_tokens)), cands[0]) if cands else rel\n",
    "            else:\n",
    "                return False  # image file not on disk -> skip\n",
    "        ann_keep = [a for a in anns_by_img[img_id] if a[\"category_id\"] in keep_cids]\n",
    "        wrote = write_label(im, ann_keep, labels_dir, catid2idx, split, rel_resolved)\n",
    "        if wrote:\n",
    "            used_rel_paths.append(rel_resolved)\n",
    "        return wrote\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=16) as ex:\n",
    "        futures = [ex.submit(process, iid) for iid in candidates]\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=f\"Writing {split} labels\"):\n",
    "            ok += 1 if f.result() else 0\n",
    "\n",
    "    print(f\"Wrote {ok} label files to {labels_dir}\")\n",
    "    return yolo_names, used_rel_paths\n",
    "\n",
    "# Run for train/val\n",
    "names_train, used_train = convert_split(TRAIN_JSON, IM_TRAIN, LB_TRAIN, TARGET_NAMES, split=\"train\")\n",
    "names_val,   used_val   = convert_split(VAL_JSON,   IM_VAL,   LB_VAL,   TARGET_NAMES, split=\"val\")\n",
    "\n",
    "# Final names in YOUR requested order (from train mapping)\n",
    "YOLO_NAMES = names_train\n",
    "print(\"\\nYOLO class order (index -> name):\")\n",
    "for i, n in enumerate(YOLO_NAMES):\n",
    "    print(f\" {i:2d} -> {n}\")\n",
    "# Save image lists (POSIX/forward-slash paths for robustness)\n",
    "train_list = [(IM_TRAIN / p).as_posix() for p in used_train]\n",
    "val_list   = [(IM_VAL   / p).as_posix() for p in used_val]\n",
    "\n",
    "(DRIVE_O365 / \"train_images.txt\").write_text(\"\\n\".join(train_list), encoding=\"utf-8\")\n",
    "(DRIVE_O365 / \"val_images.txt\").write_text(\"\\n\".join(val_list),   encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Saved lists:\\n  {DRIVE_O365/'train_images.txt'}  ({len(train_list):,} lines)\\n  {DRIVE_O365/'val_images.txt'}    ({len(val_list):,} lines)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "tQusj4AZjMY8",
    "outputId": "ced98df3-b753-481c-ea72-fd6f6aef928f"
   },
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# ==== CONFIG ====\n",
    "DATA_ROOT   = Path(r\"/content/drive/MyDrive/ultralytics_datasets/Objects365/\")\n",
    "IM_TRAIN    = DATA_ROOT / \"images\" / \"train\"\n",
    "IM_VAL      = DATA_ROOT / \"images\" / \"val\"\n",
    "LB_TRAIN    = DATA_ROOT / \"labels\" / \"train\"\n",
    "LB_VAL      = DATA_ROOT / \"labels\" / \"val\"\n",
    "\n",
    "# Subset destination\n",
    "SUBSET_ROOT = Path(r\"/content/drive/MyDrive/ultralytics_datasets/O365_vehicle13_subset\")\n",
    "S_IM_TRN    = SUBSET_ROOT / \"images\" / \"train\"\n",
    "S_IM_VAL    = SUBSET_ROOT / \"images\" / \"val\"\n",
    "S_LB_TRN    = SUBSET_ROOT / \"labels\" / \"train\"\n",
    "S_LB_VAL    = SUBSET_ROOT / \"labels\" / \"val\"\n",
    "for p in [S_IM_TRN, S_IM_VAL, S_LB_TRN, S_LB_VAL]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# YOLO class list in the order you created labels (0..12)\n",
    "YOLO_NAMES = [\n",
    "    \"Car\",\"SUV\",\"Bicycle\",\"Van\",\"Bus\",\"Motorcycle\",\"Truck\",\"Pickup Truck\",\n",
    "    \"Machinery Vehicle\",\"Sports Car\",\"Fire Truck\",\"Heavy Truck\",\"Ambulance\"\n",
    "]\n",
    "TARGET_CLASS_IDS = set(range(len(YOLO_NAMES)))  # {0..12}\n",
    "\n",
    "# Caps — tune these to shrink the set\n",
    "CAP_PER_CLASS_TRAIN = 10000   # e.g., keep up to 10k images per class for train\n",
    "CAP_PER_CLASS_VAL   = 2000    # e.g., keep up to 2k images per class for val\n",
    "MAX_TOTAL_TRAIN     = None    # or an integer to hard-cap total train images\n",
    "MAX_TOTAL_VAL       = None    # or an integer to hard-cap total val images\n",
    "\n",
    "USE_HARDLINKS = True  # hard link (fast, no extra disk) on same drive; falls back to copy on failure\n",
    "\n",
    "# ==== UTIL ====\n",
    "def label_path_from_img(img_path: Path, split: str) -> Path:\n",
    "    # convert ...\\images\\{split}\\...jpg to ...\\labels\\{split}\\...txt\n",
    "    rel = img_path.relative_to(IM_TRAIN if split==\"train\" else IM_VAL)\n",
    "    return (LB_TRAIN if split==\"train\" else LB_VAL) / rel.with_suffix(\".txt\")\n",
    "\n",
    "def read_classes_in_label(lbl_path: Path):\n",
    "    \"\"\"Return a set of class ids present in a YOLO .txt label file.\"\"\"\n",
    "    s = set()\n",
    "    if not lbl_path.exists():\n",
    "        return s\n",
    "    with open(lbl_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            if not line: continue\n",
    "            parts=line.split()\n",
    "            try:\n",
    "                cid = int(parts[0])\n",
    "            except Exception:\n",
    "                continue\n",
    "            s.add(cid)\n",
    "    return s\n",
    "\n",
    "def link_or_copy(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists():\n",
    "        return\n",
    "    try:\n",
    "        if USE_HARDLINKS:\n",
    "            os.link(src, dst)  # hard link (same volume)\n",
    "        else:\n",
    "            shutil.copy2(src, dst)\n",
    "    except Exception:\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "def choose_subset(split: str, cap_per_class: int, max_total=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    Build a balanced subset:\n",
    "    - parse labels to know which classes are present per image\n",
    "    - allocate each image to the 'rarest' class it contains (to balance)\n",
    "    - stop at per-class cap\n",
    "    \"\"\"\n",
    "    if split == \"train\":\n",
    "        img_root, lb_root, s_im_root, s_lb_root = IM_TRAIN, LB_TRAIN, S_IM_TRN, S_LB_TRN\n",
    "    else:\n",
    "        img_root, lb_root, s_im_root, s_lb_root = IM_VAL, LB_VAL, S_IM_VAL, S_LB_VAL\n",
    "\n",
    "    # collect all label files under labels/{split}\n",
    "    label_files = list(lb_root.rglob(\"*.txt\"))\n",
    "    if shuffle:\n",
    "        random.Random(1337).shuffle(label_files)\n",
    "\n",
    "    class_counts = Counter()\n",
    "    selected = []  # list of (img_path, lbl_path)\n",
    "    for lbl in label_files:\n",
    "        # infer image path by mirroring labels->images\n",
    "        rel = lbl.relative_to(lb_root)\n",
    "        img = (img_root / rel).with_suffix(\".jpg\")\n",
    "        if not img.exists():\n",
    "            # try common alternate extensions\n",
    "            for ext in [\".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\"]:\n",
    "                if (img_root / rel).with_suffix(ext).exists():\n",
    "                    img = (img_root / rel).with_suffix(ext)\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "        # read present classes\n",
    "        present = read_classes_in_label(lbl) & TARGET_CLASS_IDS\n",
    "        if not present:\n",
    "            continue\n",
    "\n",
    "        # choose the rarest present class to balance\n",
    "        rarest = min(present, key=lambda c: class_counts[c])\n",
    "        if class_counts[rarest] >= cap_per_class:\n",
    "            continue\n",
    "\n",
    "        selected.append((img, lbl))\n",
    "        class_counts[rarest] += 1\n",
    "\n",
    "        if max_total and len(selected) >= max_total:\n",
    "            break\n",
    "\n",
    "        # early exit if all classes reached cap\n",
    "        if all(class_counts[c] >= cap_per_class for c in TARGET_CLASS_IDS):\n",
    "            break\n",
    "\n",
    "    # materialize (hard-link/copy) into subset\n",
    "    for img, lbl in selected:\n",
    "        rel_img = img.relative_to(img_root)\n",
    "        dst_img = s_im_root / rel_img\n",
    "        link_or_copy(img, dst_img)\n",
    "\n",
    "        rel_lbl = lbl.relative_to(lb_root)\n",
    "        dst_lbl = s_lb_root / rel_lbl\n",
    "        link_or_copy(lbl, dst_lbl)\n",
    "\n",
    "    print(f\"[{split}] -> kept {len(selected)} images\")\n",
    "    print(\" per-class counts:\", dict(class_counts))\n",
    "    return selected\n",
    "\n",
    "sel_train = choose_subset(\"train\", cap_per_class=CAP_PER_CLASS_TRAIN, max_total=MAX_TOTAL_TRAIN)\n",
    "sel_val   = choose_subset(\"val\",   cap_per_class=CAP_PER_CLASS_VAL,   max_total=MAX_TOTAL_VAL)\n",
    "\n",
    "# Write subset image lists (forward slashes)\n",
    "train_list = [(S_IM_TRN / (p[0].relative_to(IM_TRAIN))).as_posix() for p in sel_train]\n",
    "val_list   = [(S_IM_VAL / (p[0].relative_to(IM_VAL))).as_posix()   for p in sel_val]\n",
    "\n",
    "(SUBSET_ROOT / \"train_images.txt\").write_text(\"\\n\".join(train_list), encoding=\"utf-8\")\n",
    "(SUBSET_ROOT / \"val_images.txt\").write_text(\"\\n\".join(val_list), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Subset lists:\")\n",
    "print(\" \", SUBSET_ROOT / \"train_images.txt\", len(train_list))\n",
    "print(\" \", SUBSET_ROOT / \"val_images.txt\",   len(val_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un8HzzcMush7"
   },
   "outputs": [],
   "source": [
    "import yaml, warnings\n",
    "from PIL import Image\n",
    "# Optional: disable PIL DecompressionBomb warnings (large panoramas etc.)\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL.Image\")\n",
    "\n",
    "DATASET_YAML = SUBSET_ROOT / \"o365_vehicle13_subset.yaml\"\n",
    "yaml.safe_dump({\n",
    "    \"train\": (SUBSET_ROOT / \"train_images.txt\").as_posix(),\n",
    "    \"val\":   (SUBSET_ROOT / \"val_images.txt\").as_posix(),\n",
    "    \"nc\": len(YOLO_NAMES),\n",
    "    \"names\": YOLO_NAMES\n",
    "}, open(DATASET_YAML, \"w\", encoding=\"utf-8\"), sort_keys=False)\n",
    "\n",
    "print(\"Wrote:\", DATASET_YAML)\n",
    "print(DATASET_YAML.read_text()[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttIOhooxGOmu",
    "outputId": "de17f609-a2f1-4bd9-858c-3157f36991a1"
   },
   "outputs": [],
   "source": [
    "! ls \"/content/drive/MyDrive/ultralytics_datasets/Objects365/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXFBT9DwufRX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmBZTH1CmOre",
    "outputId": "01d0962d-70fd-4758-f339-49e0c4db6c7b"
   },
   "outputs": [],
   "source": [
    "!unzip -o \"/content/drive/MyDrive/ultralytics_datasets/Objects365/labels0.zip\" -d \"/content/drive/MyDrive/ultralytics_datasets/Objects365/labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmEmK09-GBvH",
    "outputId": "66799bd8-c9ae-4054-a423-dcfdc003fe23"
   },
   "outputs": [],
   "source": [
    "!ls -lh \"/content/drive/MyDrive/ultralytics_datasets/Objects365/labels0.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zj1BaIDwlGhQ"
   },
   "outputs": [],
   "source": [
    "!mv /content/drive/MyDrive/ultralytics_datasets/Objects365/labels/labels/* /content/drive/MyDrive/ultralytics_datasets/Objects365/labels/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1L_j-pfc5rT",
    "outputId": "a50b039e-6f27-4550-dc74-413d74fe3e0e"
   },
   "outputs": [],
   "source": [
    "!ls -lh \"/content/drive/MyDrive/ultralytics_datasets/Objects365/labels/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q181M9BQ6gpS",
    "outputId": "a8cbc227-3e40-4b0c-b57d-227ea8353c20"
   },
   "outputs": [],
   "source": [
    "!find \"/content/drive/MyDrive/ultralytics_datasets/Objects365/labels/val\"   -type f -name \"*.txt\" | wc -l\n",
    "!find \"/content/drive/MyDrive/ultralytics_datasets/Objects365/labels/train\" -type f -name \"*.txt\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "FV7Wo06X49bV",
    "outputId": "16975558-a5ea-4163-9851-55710381967b"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "DATASET_YAML = DRIVE_O365/\"objects365_vehicle13_on_drive.yaml\"\n",
    "yaml_obj = {\n",
    "    \"train\": str(DRIVE_O365/\"train_images.txt\"),  # text files of absolute image paths\n",
    "    \"val\":   str(DRIVE_O365/\"val_images.txt\"),\n",
    "    \"nc\": len(YOLO_NAMES),\n",
    "    \"names\": YOLO_NAMES\n",
    "}\n",
    "with open(DATASET_YAML, \"w\") as f:\n",
    "    yaml.safe_dump(yaml_obj, f, sort_keys=False)\n",
    "\n",
    "print(\"Wrote dataset YAML:\", DATASET_YAML)\n",
    "print(DATASET_YAML.read_text()[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZpvlq4N1emb",
    "outputId": "822fe9a8-a54b-487c-96d8-8766a0ca2416"
   },
   "outputs": [],
   "source": [
    "!head -n 10 /content/drive/MyDrive/ultralytics_datasets/Objects365/train_images.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc99DtScF2d-",
    "outputId": "b587bcc7-e04a-4944-8b6f-813cd3e9ac62"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PB102zqh3fDC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icabP1u63fmC",
    "outputId": "cf708c84-f505-443a-85c6-e784f23e8626"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.228)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch>=1.8.0->ultralytics) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in /usr/local/lib/python3.12/dist-packages (from polars->ultralytics) (1.35.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iK_pNnJI5A0Y",
    "outputId": "ef1b2e8e-ca91-44ba-b2f1-65bd6843ce29",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training yolo12x ===\n",
      "Ultralytics 8.3.228 🚀 Python-3.12.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA H200 NVL, 143156MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/workspace/O365_vehicle13_subset_2/o365_vehicle13_subset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo12x, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/ultralytics_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/ultralytics_runs/yolo12x, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=64, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=13\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  4   9512128  ultralytics.nn.modules.block.A2C2f           [768, 768, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  4   9512128  ultralytics.nn.modules.block.A2C2f           [768, 768, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   4727040  ultralytics.nn.modules.block.A2C2f           [1536, 768, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2   1331328  ultralytics.nn.modules.block.A2C2f           [1536, 384, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   4579584  ultralytics.nn.modules.block.A2C2f           [1152, 768, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 21        [14, 17, 20]  1   3160567  ultralytics.nn.modules.head.Detect           [13, [384, 768, 768]]         \n",
      "YOLOv12x summary: 488 layers, 59,133,399 parameters, 59,133,383 gradients, 199.9 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1644.5±720.0 MB/s, size: 148.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 54.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA H200 NVL) 139.80G total, 42.52G reserved, 0.52G allocated, 96.76G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    59133399       199.9         4.832         36.06           154        (1, 3, 640, 640)                    list\n",
      "    59133399       399.8         7.422         40.11         81.74        (2, 3, 640, 640)                    list\n",
      "    59133399       799.6        12.767         47.62         86.96        (4, 3, 640, 640)                    list\n",
      "    59133399        1599        23.113         55.12         117.3        (8, 3, 640, 640)                    list\n",
      "    59133399        3198        43.904         84.33         187.5       (16, 3, 640, 640)                    list\n",
      "    59133399        6397        85.321         160.9         342.2       (32, 3, 640, 640)                    list\n",
      "    59133399   1.279e+04        21.630         311.6         748.4       (64, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 21 for CUDA:0 99.86G/139.80G (71%) ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2145.9±2698.4 MB/s, size: 1976.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 31.0Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (49.9GB RAM): 100% ━━━━━━━━━━━━ 61975/61975 679.5it/s 1:31<0.1ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 342.8±132.4 MB/s, size: 200.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/val/patch0.cache... 5923 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5923/5923 4.6Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00500342.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00515987.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch14/objects365_v1_00693178.jpg: 4 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (4.8GB RAM): 100% ━━━━━━━━━━━━ 5923/5923 1.9Kit/s 3.1s0.1s\n",
      "Plotting labels to /content/ultralytics_runs/yolo12x/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.0004921875), 211 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 64 dataloader workers\n",
      "Logging results to \u001b[1m/content/ultralytics_runs/yolo12x\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/300      52.5G      1.259      1.975      1.392         15        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:50<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.349      0.302       0.25      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/300      51.6G       1.22      1.855      1.366         30        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:30<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.3it/s 26.6s0.2s\n",
      "                   all       5923      23154      0.402      0.349      0.311      0.217\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/300      51.5G      1.141      1.695      1.311         17        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.9s0.2s\n",
      "                   all       5923      23154       0.44      0.398      0.368      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/300      51.4G      1.079      1.571      1.267         47        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:17<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.1s0.2s\n",
      "                   all       5923      23154      0.494      0.436      0.427      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/300      51.4G      1.035      1.487      1.241         37        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:22<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154      0.517      0.458      0.458      0.342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/300      51.4G      1.006      1.423       1.22         47        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:22<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.533      0.473      0.477      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/300      51.4G     0.9786      1.373      1.199         16        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:22<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.548      0.495      0.498       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/300      51.4G     0.9561       1.33      1.187         28        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:21<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154      0.562      0.497      0.509      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/300      51.5G     0.9451      1.298      1.177         28        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:21<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.4s0.2s\n",
      "                   all       5923      23154      0.567      0.514      0.523      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/300      51.4G     0.9322       1.27      1.168         27        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:21<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.4s0.2s\n",
      "                   all       5923      23154      0.578      0.519      0.533       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/300      51.4G     0.9152      1.241      1.159         23        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:20<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.4s0.2s\n",
      "                   all       5923      23154      0.582      0.522      0.539      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/300      51.5G     0.9056      1.222      1.151         37        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:20<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.4s0.2s\n",
      "                   all       5923      23154      0.582       0.53      0.544      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/300      51.5G     0.8971        1.2      1.144         19        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:22<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.3s0.2s\n",
      "                   all       5923      23154      0.588      0.533       0.55      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/300      51.5G     0.8886      1.178       1.14         24        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:21<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.2s0.2s\n",
      "                   all       5923      23154      0.586      0.537      0.554      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/300      51.5G     0.8798      1.167      1.133         37        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:18<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.9s0.2s\n",
      "                   all       5923      23154      0.585      0.543      0.558      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/300      51.4G     0.8719      1.149       1.13         38        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:13<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.8s0.2s\n",
      "                   all       5923      23154      0.591      0.544      0.561      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/300      51.5G     0.8652      1.134      1.124         33        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:15<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.8s0.2s\n",
      "                   all       5923      23154      0.592      0.547      0.563       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/300      51.5G     0.8581      1.121      1.117         38        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:14<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.8it/s 24.7s0.2s\n",
      "                   all       5923      23154      0.594      0.549      0.565      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/300      51.5G     0.8546      1.107      1.116         35        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:14<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.8s0.2s\n",
      "                   all       5923      23154        0.6      0.548      0.567      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/300      51.5G     0.8475      1.098       1.11         13        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.8s0.2s\n",
      "                   all       5923      23154      0.606      0.547      0.569      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/300      51.4G      0.842      1.083      1.107         17        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:15<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.8s0.2s\n",
      "                   all       5923      23154      0.605      0.549       0.57      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/300      51.5G     0.8359      1.069      1.103         51        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:16<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.7s0.2s\n",
      "                   all       5923      23154      0.602      0.554      0.571      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/300      51.5G      0.835      1.063      1.102         33        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:13<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.8s0.2s\n",
      "                   all       5923      23154      0.604      0.555      0.573       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/300      51.4G     0.8312      1.054      1.097         15        640: 100% ━━━━━━━━━━━━ 2952/2952 2.9it/s 17:15<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.7s0.2s\n",
      "                   all       5923      23154      0.604      0.556      0.574      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/300      51.4G     0.8272      1.045      1.097         35        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:20<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.8it/s 24.6s0.2s\n",
      "                   all       5923      23154      0.603      0.559      0.575      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/300      51.5G     0.8218      1.034      1.091         32        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:20<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.605      0.559      0.577      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/300      51.4G      0.817      1.026      1.089         19        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:29<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154      0.609      0.556      0.578      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/300      51.5G     0.8148      1.016      1.085         20        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154      0.611      0.556      0.579      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/300      51.5G     0.8126      1.005      1.086         70        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.614      0.557      0.581      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/300      51.5G     0.8094          1      1.085         43        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:25<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.613      0.558      0.582       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/300      51.4G     0.8052     0.9886       1.08         44        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 25.1s0.2s\n",
      "                   all       5923      23154      0.615      0.558      0.583      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/300      51.5G     0.8013     0.9825      1.079         30        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154      0.617      0.559      0.584      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/300      51.4G     0.7981     0.9787      1.079         23        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.617      0.561      0.585      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/300      51.4G     0.7964     0.9684      1.077         12        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.619      0.561      0.586      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/300      51.5G     0.7937     0.9592      1.073         29        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:25<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.618      0.564      0.587      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/300      51.4G     0.7879     0.9531      1.071         19        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154       0.62      0.563      0.588      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/300      51.4G      0.789      0.944      1.064         16        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.9s0.2s\n",
      "                   all       5923      23154      0.621      0.563      0.589      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/300      51.4G     0.7834     0.9345      1.065         14        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.623      0.561      0.589      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/300      51.5G     0.7833     0.9275      1.065         31        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:25<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.624      0.561      0.589      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/300      51.4G     0.7792     0.9224      1.063         15        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:25<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154      0.623      0.562       0.59      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/300      51.4G     0.7768     0.9192      1.063         60        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154       0.62      0.566       0.59      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/300      51.5G     0.7755     0.9097      1.061         77        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.7s0.2s\n",
      "                   all       5923      23154      0.618      0.569      0.591      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/300      51.4G     0.7715     0.9028      1.058         12        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.2s0.2s\n",
      "                   all       5923      23154      0.616      0.571      0.591      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/300      51.4G     0.7708     0.8941      1.055         15        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.614      0.573      0.591      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/300      51.5G     0.7698     0.8878      1.054         21        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:25<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.617      0.572      0.591      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/300      51.5G      0.765     0.8818      1.052         20        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:27<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.8s0.2s\n",
      "                   all       5923      23154       0.62      0.569      0.592      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/300      51.5G     0.7612     0.8716      1.048         23        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:22<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.2s0.2s\n",
      "                   all       5923      23154      0.619       0.57      0.591      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/300      51.4G      0.765     0.8717       1.05         32        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.617      0.573      0.591      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/300      51.5G     0.7599     0.8627      1.049         40        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:25<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.619      0.572      0.591      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/300      51.4G     0.7572     0.8555      1.046         38        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.4s0.2s\n",
      "                   all       5923      23154      0.623      0.569      0.591      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/300      51.4G      0.757     0.8539      1.045         30        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.623      0.569      0.591      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/300      51.4G     0.7541     0.8438      1.044         18        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.622       0.57       0.59      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/300      51.4G      0.751     0.8361      1.041         31        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:26<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.622      0.569       0.59      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/300      51.5G     0.7497     0.8294      1.038         41        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:47<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 25.0s0.2s\n",
      "                   all       5923      23154      0.622      0.568      0.589      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/300      51.4G     0.7486     0.8228      1.035         40        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:35<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.623      0.569      0.588      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/300      51.4G     0.7475     0.8189      1.039         37        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:34<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 4.7it/s 30.5s0.2s\n",
      "                   all       5923      23154      0.621      0.568      0.587      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/300      51.4G     0.7445     0.8132      1.035         22        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:26<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.5s0.2s\n",
      "                   all       5923      23154      0.615      0.573      0.587      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/300      51.4G     0.7457       0.81      1.036         28        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:26<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.2s0.2s\n",
      "                   all       5923      23154      0.615      0.571      0.586      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/300      51.5G     0.7416      0.801      1.032         18        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:28<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.9s0.2s\n",
      "                   all       5923      23154      0.618      0.568      0.586      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/300      51.4G      0.737     0.7958      1.031         35        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:25<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.619      0.566      0.585      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/300      51.5G       0.74     0.7928      1.031         27        640: 100% ━━━━━━━━━━━━ 2952/2952 2.7it/s 18:03<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 4.1it/s 34.7s0.2ss\n",
      "                   all       5923      23154      0.617      0.569      0.584      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/300      51.4G     0.7364     0.7837       1.03         38        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.2s0.2s\n",
      "                   all       5923      23154      0.613      0.573      0.584       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/300      51.4G     0.7352     0.7797       1.03         20        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:29<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 4.6it/s 30.8s0.2s\n",
      "                   all       5923      23154      0.614      0.571      0.583      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/300      51.5G     0.7316     0.7717      1.023         24        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:20<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 25.1s0.2s\n",
      "                   all       5923      23154      0.615       0.57      0.582      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/300      51.5G     0.7319     0.7685      1.023         14        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:19<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.9s0.2s\n",
      "                   all       5923      23154      0.616      0.569      0.582      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/300      51.5G     0.7258     0.7596      1.021         14        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:35<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.0it/s 28.4s0.2s\n",
      "                   all       5923      23154      0.619      0.565      0.582      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/300      51.5G     0.7267     0.7589      1.023         20        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:29<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.9s0.2s\n",
      "                   all       5923      23154      0.619      0.564      0.581      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/300      51.5G     0.7265     0.7537      1.022         26        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:21<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.0it/s 28.2s0.2s\n",
      "                   all       5923      23154       0.62      0.562       0.58      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/300      51.5G     0.7256     0.7478       1.02         27        640: 100% ━━━━━━━━━━━━ 2952/2952 2.7it/s 18:00<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.5it/s 25.8s0.2s\n",
      "                   all       5923      23154      0.622      0.559       0.58      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/300      51.4G     0.7231     0.7418      1.019         43        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 24.9s0.2s\n",
      "                   all       5923      23154      0.621       0.56      0.579      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/300      51.5G     0.7213     0.7383      1.017         32        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 25.0s0.2s\n",
      "                   all       5923      23154      0.621      0.558      0.578      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/300      51.5G     0.7187     0.7321      1.017          9        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 25.0s0.2s\n",
      "                   all       5923      23154       0.62      0.557      0.577      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/300      51.4G     0.7186     0.7267      1.012         53        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:22<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.3s0.2s\n",
      "                   all       5923      23154      0.626      0.554      0.577      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/300      51.4G     0.7148     0.7238      1.013         18        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:26<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 25.1s0.2s\n",
      "                   all       5923      23154      0.618      0.561      0.576      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/300      51.4G     0.7142     0.7167      1.009         39        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:18<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.7it/s 25.0s0.2s\n",
      "                   all       5923      23154      0.617      0.562      0.575      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/300      51.5G      0.713      0.716      1.013         39        640: 100% ━━━━━━━━━━━━ 2952/2952 2.8it/s 17:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.6it/s 25.6s0.2s\n",
      "                   all       5923      23154      0.616       0.56      0.574      0.451\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 46, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "76 epochs completed in 22.636 hours.\n",
      "Optimizer stripped from /content/ultralytics_runs/yolo12x/weights/last.pt, 119.1MB\n",
      "Optimizer stripped from /content/ultralytics_runs/yolo12x/weights/best.pt, 119.1MB\n",
      "\n",
      "Validating /content/ultralytics_runs/yolo12x/weights/best.pt...\n",
      "Ultralytics 8.3.228 🚀 Python-3.12.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA H200 NVL, 143156MiB)\n",
      "YOLOv12x summary (fused): 283 layers, 59,058,359 parameters, 0 gradients, 198.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 142/142 5.4it/s 26.2s0.2s\n",
      "                   all       5923      23154      0.618       0.57      0.591      0.468\n",
      "                   Car       2560       5171      0.507      0.553      0.518      0.385\n",
      "                   SUV        994       1332      0.414      0.561      0.459      0.378\n",
      "               Bicycle        859       1482      0.725      0.632      0.697      0.495\n",
      "                   Van       1159       1737      0.554      0.453      0.471      0.361\n",
      "                   Bus        633       1140      0.703       0.54      0.598      0.483\n",
      "            Motorcycle        637       1252      0.427      0.594       0.49      0.349\n",
      "                 Truck       1153       1970      0.428      0.343      0.344      0.252\n",
      "          Pickup Truck        618        862      0.678      0.573      0.644      0.532\n",
      "     Machinery Vehicle       1041       3040      0.655      0.398      0.499      0.326\n",
      "            Sports Car        439       2571      0.828      0.673       0.81      0.687\n",
      "            Fire Truck        219        676      0.696      0.751      0.755      0.619\n",
      "           Heavy Truck        357        989      0.545      0.511      0.514        0.4\n",
      "             Ambulance        484        932      0.876      0.827      0.891      0.817\n",
      "Speed: 0.0ms preprocess, 3.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/content/ultralytics_runs/yolo12x\u001b[0m\n",
      "Ultralytics 8.3.228 🚀 Python-3.12.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA H200 NVL, 143156MiB)\n",
      "YOLOv12x summary (fused): 283 layers, 59,058,359 parameters, 0 gradients, 198.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 696.4±398.5 MB/s, size: 565.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/val/patch0.cache... 5923 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5923/5923 9.4Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00500342.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00515987.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch14/objects365_v1_00693178.jpg: 4 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 371/371 13.4it/s 27.7s<0.1s\n",
      "                   all       5923      23154      0.619      0.569      0.591      0.468\n",
      "                   Car       2560       5171      0.507      0.552      0.517      0.385\n",
      "                   SUV        994       1332      0.413      0.559      0.459      0.377\n",
      "               Bicycle        859       1482      0.729      0.632      0.697      0.495\n",
      "                   Van       1159       1737      0.553      0.451       0.47      0.361\n",
      "                   Bus        633       1140      0.704       0.54      0.599      0.483\n",
      "            Motorcycle        637       1252      0.426      0.594       0.49      0.349\n",
      "                 Truck       1153       1970      0.429      0.342      0.344      0.252\n",
      "          Pickup Truck        618        862      0.678      0.573      0.644      0.532\n",
      "     Machinery Vehicle       1041       3040      0.655      0.397      0.499      0.326\n",
      "            Sports Car        439       2571      0.829      0.673      0.809      0.687\n",
      "            Fire Truck        219        676      0.698       0.75      0.755      0.618\n",
      "           Heavy Truck        357        989      0.546      0.511      0.514        0.4\n",
      "             Ambulance        484        932      0.876      0.826      0.891      0.817\n",
      "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/runs/detect/val3\u001b[0m\n",
      "[OK] yolo12x best: yolo12x.pt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RUNS_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[SKIP] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m df = pd.DataFrame(rows).sort_values(\u001b[33m\"\u001b[39m\u001b[33mmAP50-95\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m cmp_csv = Path(\u001b[43mRUNS_DIR\u001b[49m)/PROJECT/\u001b[33m\"\u001b[39m\u001b[33mmodel_comparison.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     58\u001b[39m cmp_csv.parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     59\u001b[39m df.to_csv(cmp_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'RUNS_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "SUBSET_ROOT = Path(\"/workspace/O365_vehicle13_subset_2\")\n",
    "DATASET_YAML = SUBSET_ROOT / \"o365_vehicle13_subset.yaml\"\n",
    "DATA_YAML = str(DATASET_YAML)\n",
    "PROJECT   = \"/content/ultralytics_runs\"\n",
    "IMG_SIZE  = 640      # go 1536 or 1920 if you can afford it\n",
    "EPOCHS    = 300\n",
    "WORKERS   = 64\n",
    "\n",
    "models = [\n",
    "    # (\"/content/ultralytics_runs/yolov8x/weights/last.pt\",  \"yolov8x\"),\n",
    "    # (\"/content/ultralytics_runs/yolo11x/weights/last.pt\",  \"yolo11x\"),\n",
    "    (\"yolo12x.pt\",  \"yolo12x\"),  # skipped gracefully if not available in your wheel\n",
    "]\n",
    "\n",
    "common = dict(\n",
    "    data=DATA_YAML,\n",
    "    imgsz=IMG_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    batch=-1,          # auto-batch for A100\n",
    "    device=0,\n",
    "    optimizer=\"AdamW\",\n",
    "    cos_lr=True,\n",
    "    lr0=0.001,\n",
    "    weight_decay=0.0005,\n",
    "    patience=30,\n",
    "    amp=False,\n",
    "    workers=WORKERS,\n",
    "    close_mosaic=10,\n",
    "    cache=True,       # set True only if subset fits RAM/SSD\n",
    "    project=PROJECT,\n",
    "    exist_ok=True,\n",
    "    save_period = 1,\n",
    "    # resume=True,\n",
    ")\n",
    "\n",
    "rows, best_ckpts = [], {}\n",
    "for w, tag in models:\n",
    "    print(f\"\\n=== Training {tag} ===\")\n",
    "    try:\n",
    "        model = YOLO(w)\n",
    "        model.train(name=tag, **common)\n",
    "        m = model.val(data=DATA_YAML, imgsz=IMG_SIZE)\n",
    "        rows.append({\"model\": tag,\n",
    "                     \"mAP50-95\": float(m.box.map),\n",
    "                     \"mAP50\": float(m.box.map50),\n",
    "                     \"mAP75\": float(m.box.map75)})\n",
    "        best_ckpts[tag] = str(Path(model.ckpt_path))\n",
    "        print(f\"[OK] {tag} best: {best_ckpts[tag]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] {tag}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"mAP50-95\", ascending=False)\n",
    "cmp_csv = Path(RUNS_DIR)/PROJECT/\"model_comparison.csv\"\n",
    "cmp_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(cmp_csv, index=False)\n",
    "display(df)\n",
    "print(\"Saved comparison CSV to:\", cmp_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHrh5LfA5DX8"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import glob\n",
    "\n",
    "if best_ckpts:\n",
    "    best = max(rows, key=lambda r: r[\"mAP50-95\"])[\"model\"]\n",
    "    print(\"Best model:\", best, \"->\", best_ckpts[best])\n",
    "    model = YOLO(best_ckpts[best])\n",
    "\n",
    "    # Pick a few validation images\n",
    "    sample_imgs = []\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"):\n",
    "        sample_imgs += glob.glob(str(IM_VAL / \"**\" / ext), recursive=True)\n",
    "    sample_imgs = sample_imgs[:8]\n",
    "    print(\"Predicting on\", len(sample_imgs), \"images...\")\n",
    "\n",
    "    model.predict(\n",
    "        source=sample_imgs,\n",
    "        imgsz=IMG_SIZE,\n",
    "        conf=0.35,\n",
    "        save=True,\n",
    "        project=PROJECT,\n",
    "        name=\"predict_samples\",\n",
    "        device=0\n",
    "    )\n",
    "    print(\"Predictions saved under:\", Path(RUNS_DIR)/PROJECT/\"predict_samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TZuMLBNE5Eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training yolov8x ===\n",
      "Ultralytics 8.3.228 🚀 Python-3.12.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA H200 NVL, 143156MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/workspace/O365_vehicle13_subset_2/o365_vehicle13_subset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/ultralytics_runs/yolov8x/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8x, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/ultralytics_runs, rect=False, resume=/content/ultralytics_runs/yolov8x/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/ultralytics_runs/yolov8x, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=64, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8730487  ultralytics.nn.modules.head.Detect           [13, [320, 640, 640]]         \n",
      "Model summary: 209 layers, 68,165,127 parameters, 68,165,111 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 595/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 724.7±118.3 MB/s, size: 148.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 44.2Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA H200 NVL) 139.80G total, 14.21G reserved, 0.58G allocated, 125.01G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    68165127       258.2         3.624         45.64         329.1        (1, 3, 640, 640)                    list\n",
      "    68165127       516.4         4.784         37.79         270.6        (2, 3, 640, 640)                    list\n",
      "    68165127        1033         6.619         59.67         270.1        (4, 3, 640, 640)                    list\n",
      "    68165127        2065        10.075         89.51         287.7        (8, 3, 640, 640)                    list\n",
      "    68165127        4131        16.094         54.04         247.9       (16, 3, 640, 640)                    list\n",
      "    68165127        8262        28.003         95.31         263.8       (32, 3, 640, 640)                    list\n",
      "    68165127   1.652e+04        51.280         284.3         284.5       (64, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 95 for CUDA:0 89.70G/139.80G (64%) ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 612.1±486.9 MB/s, size: 1976.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 17.4Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (49.9GB RAM): 100% ━━━━━━━━━━━━ 61975/61975 1.5Kit/s 40.8s<0.1ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 396.7±226.0 MB/s, size: 200.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/val/patch0.cache... 5923 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5923/5923 4.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00500342.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00515987.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch14/objects365_v1_00693178.jpg: 4 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (4.8GB RAM): 100% ━━━━━━━━━━━━ 5923/5923 1.3Kit/s 4.4s<0.0s\n",
      "Plotting labels to /content/ultralytics_runs/yolov8x/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0007421875), 103 bias(decay=0.0)\n",
      "[SKIP] yolov8x: /content/ultralytics_runs/yolov8x/weights/last.pt training to 300 epochs is finished, nothing to resume.\n",
      "Start a new training without resuming, i.e. 'yolo train model=/content/ultralytics_runs/yolov8x/weights/last.pt'\n",
      "\n",
      "=== Training yolo11x ===\n",
      "Ultralytics 8.3.228 🚀 Python-3.12.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA H200 NVL, 143156MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/workspace/O365_vehicle13_subset_2/o365_vehicle13_subset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/ultralytics_runs/yolo11x/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11x, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/ultralytics_runs, rect=False, resume=/content/ultralytics_runs/yolo11x/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/ultralytics_runs/yolo11x, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=64, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
      " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
      " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
      " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 23        [16, 19, 22]  1   3160567  ultralytics.nn.modules.head.Detect           [13, [384, 768, 768]]         \n",
      "YOLO11x summary: 357 layers, 56,888,791 parameters, 56,888,775 gradients, 195.5 GFLOPs\n",
      "\n",
      "Transferred 1015/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 758.8±110.5 MB/s, size: 148.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 34.2Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA H200 NVL) 139.80G total, 4.11G reserved, 0.50G allocated, 135.20G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    56888791       195.5         3.540         67.47         112.6        (1, 3, 640, 640)                    list\n",
      "    56888791       391.1         4.758         53.49         97.35        (2, 3, 640, 640)                    list\n",
      "    56888791       782.1         7.105         66.62         103.3        (4, 3, 640, 640)                    list\n",
      "    56888791        1564        11.253         76.12         89.79        (8, 3, 640, 640)                    list\n",
      "    56888791        3128        19.397         89.31         115.5       (16, 3, 640, 640)                    list\n",
      "    56888791        6257        34.871         102.8         158.4       (32, 3, 640, 640)                    list\n",
      "    56888791   1.251e+04        65.951           167         242.7       (64, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 78 for CUDA:0 84.63G/139.80G (61%) ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3438.0±2740.1 MB/s, size: 1976.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 15.4Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (49.9GB RAM): 100% ━━━━━━━━━━━━ 61975/61975 1.0Kit/s 1:011<0.1ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 440.1±231.9 MB/s, size: 200.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/val/patch0.cache... 5923 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5923/5923 4.7Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00500342.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00515987.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch14/objects365_v1_00693178.jpg: 4 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (4.8GB RAM): 100% ━━━━━━━━━━━━ 5923/5923 1.1Kit/s 5.6s0.1ss\n",
      "Plotting labels to /content/ultralytics_runs/yolo11x/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.003, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.000609375), 173 bias(decay=0.0)\n",
      "[SKIP] yolo11x: /content/ultralytics_runs/yolo11x/weights/last.pt training to 300 epochs is finished, nothing to resume.\n",
      "Start a new training without resuming, i.e. 'yolo train model=/content/ultralytics_runs/yolo11x/weights/last.pt'\n",
      "\n",
      "=== Training yolo12x ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-298 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/venv/main/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/venv/main/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/venv/main/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/venv/main/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 52, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/venv/main/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/connection.py\", line 525, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/connection.py\", line 953, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228 🚀 Python-3.12.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA H200 NVL, 143156MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/workspace/O365_vehicle13_subset_2/o365_vehicle13_subset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/ultralytics_runs/yolo12x/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo12x, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/ultralytics_runs, rect=False, resume=/content/ultralytics_runs/yolo12x/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/ultralytics_runs/yolo12x, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=64, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  4   9512128  ultralytics.nn.modules.block.A2C2f           [768, 768, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  4   9512128  ultralytics.nn.modules.block.A2C2f           [768, 768, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   4727040  ultralytics.nn.modules.block.A2C2f           [1536, 768, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2   1331328  ultralytics.nn.modules.block.A2C2f           [1536, 384, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   4579584  ultralytics.nn.modules.block.A2C2f           [1152, 768, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 21        [14, 17, 20]  1   3160567  ultralytics.nn.modules.head.Detect           [13, [384, 768, 768]]         \n",
      "YOLOv12x summary: 488 layers, 59,133,399 parameters, 59,133,383 gradients, 199.9 GFLOPs\n",
      "\n",
      "Transferred 1245/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1108.5±575.0 MB/s, size: 148.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 36.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA H200 NVL) 139.80G total, 2.23G reserved, 0.51G allocated, 137.06G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    59133399       199.9         4.893         79.58         61.33        (1, 3, 640, 640)                    list\n",
      "    59133399       399.8         7.495         80.38         68.89        (2, 3, 640, 640)                    list\n",
      "    59133399       799.6        12.765          99.7         71.15        (4, 3, 640, 640)                    list\n",
      "    59133399        1599        23.060         108.5         101.7        (8, 3, 640, 640)                    list\n",
      "    59133399        3198        43.877         117.1         178.5       (16, 3, 640, 640)                    list\n",
      "    59133399        6397        86.887         161.5         337.3       (32, 3, 640, 640)                    list\n",
      "    59133399   1.279e+04        22.574         618.5         857.7       (64, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 30 for CUDA:0 84.09G/139.80G (60%) ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1763.5±1108.4 MB/s, size: 1976.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/train/patch0.cache... 61975 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61975/61975 15.7Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch0/objects365_v1_00013513.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch1/objects365_v1_00088783.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00496691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch10/objects365_v1_00508641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch13/objects365_v1_00625668.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch14/objects365_v1_00694069.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch15/objects365_v1_00734477.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00093041.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch2/objects365_v1_00101882.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch3/objects365_v1_00142288.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00185958.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch4/objects365_v1_00208452.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00282675.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch6/objects365_v1_00314884.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00333363.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00344610.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch7/objects365_v1_00353491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch8/objects365_v1_00405534.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/workspace/O365_vehicle13_subset_2/images/train/patch9/objects365_v1_00461620.jpg: 1 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (49.9GB RAM): 100% ━━━━━━━━━━━━ 61975/61975 919.3it/s 1:070.0sss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 415.9±189.2 MB/s, size: 200.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/O365_vehicle13_subset_2/labels/val/patch0.cache... 5923 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5923/5923 4.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00500342.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch10/objects365_v1_00515987.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/workspace/O365_vehicle13_subset_2/images/val/patch14/objects365_v1_00693178.jpg: 4 duplicate labels removed\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (4.8GB RAM): 100% ━━━━━━━━━━━━ 5923/5923 2.0Kit/s 2.9s0.0s\n",
      "Plotting labels to /content/ultralytics_runs/yolo12x/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00046875), 211 bias(decay=0.0)\n",
      "[SKIP] yolo12x: /content/ultralytics_runs/yolo12x/weights/last.pt training to 300 epochs is finished, nothing to resume.\n",
      "Start a new training without resuming, i.e. 'yolo train model=/content/ultralytics_runs/yolo12x/weights/last.pt'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mAP50-95'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_32388/4022140335.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     75\u001b[39m         print(f\"[SKIP] {tag}: {e}\")\n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# --- Save comparison CSV ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m df = pd.DataFrame(rows).sort_values(\u001b[33m\"mAP50-95\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     79\u001b[39m cmp_csv = Path(PROJECT) / \u001b[33m\"model_comparison.csv\"\u001b[39m\n\u001b[32m     80\u001b[39m cmp_csv.parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     81\u001b[39m df.to_csv(cmp_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m/venv/main/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7207\u001b[39m             )\n\u001b[32m   7208\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7209\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7210\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7211\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7212\u001b[39m \n\u001b[32m   7213\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7214\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m/venv/main/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'mAP50-95'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "SUBSET_ROOT = Path(\"/workspace/O365_vehicle13_subset_2\")\n",
    "DATASET_YAML = SUBSET_ROOT / \"o365_vehicle13_subset.yaml\"\n",
    "DATA_YAML = str(DATASET_YAML)\n",
    "PROJECT   = \"/content/ultralytics_runs\"\n",
    "IMG_SIZE  = 640      # go 1536 or 1920 if you can afford it\n",
    "EPOCHS    = 300\n",
    "WORKERS   = 64\n",
    "\n",
    "# Define this if not already:\n",
    "IM_VAL = SUBSET_ROOT / \"images\" / \"val\"   # adjust if your val path differs\n",
    "\n",
    "models = [\n",
    "    (\"/content/ultralytics_runs/yolov8x/weights/last.pt\",  \"yolov8x\"),\n",
    "    (\"/content/ultralytics_runs/yolo11x/weights/last.pt\",  \"yolo11x\"),\n",
    "    (\"/content/ultralytics_runs/yolo12x/weights/last.pt\",  \"yolo12x\"),  # skipped gracefully if not available in your wheel\n",
    "]\n",
    "\n",
    "common = dict(\n",
    "    data=DATA_YAML,\n",
    "    imgsz=IMG_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    batch=-1,          # auto-batch\n",
    "    device=0,\n",
    "    optimizer=\"AdamW\",\n",
    "    cos_lr=True,\n",
    "    lr0=0.003,\n",
    "    weight_decay=0.0005,\n",
    "    patience=30,\n",
    "    workers=WORKERS,\n",
    "    cache=True,       # True only if subset fits RAM/SSD\n",
    "    project=PROJECT,\n",
    "    exist_ok=True,    # ok to keep\n",
    "    resume=True,      # resume interrupted runs\n",
    ")\n",
    "\n",
    "rows, best_ckpts = [], {}\n",
    "\n",
    "for w, tag in models:\n",
    "    print(f\"\\n=== Training {tag} ===\")\n",
    "    try:\n",
    "        model = YOLO(w)\n",
    "        model.train(name=tag, **common)\n",
    "\n",
    "        # --- NEW: explicitly use best.pt for validation ---\n",
    "        run_dir   = Path(PROJECT) / tag\n",
    "        best_path = run_dir / \"weights\" / \"best.pt\"\n",
    "\n",
    "        if best_path.is_file():\n",
    "            print(f\"Using best checkpoint for {tag}: {best_path}\")\n",
    "            eval_model = YOLO(best_path)\n",
    "            best_ckpts[tag] = str(best_path)\n",
    "        else:\n",
    "            # Fallback to the current model (last.pt) if best.pt not found\n",
    "            print(f\"[WARN] best.pt not found for {tag}, using current model weights\")\n",
    "            eval_model = model\n",
    "            best_ckpts[tag] = str(Path(w))\n",
    "\n",
    "        m = eval_model.val(data=DATA_YAML, imgsz=IMG_SIZE)\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": tag,\n",
    "            \"mAP50-95\": float(m.box.map),\n",
    "            \"mAP50\": float(m.box.map50),\n",
    "            \"mAP75\": float(m.box.map75),\n",
    "        })\n",
    "\n",
    "        print(f\"[OK] {tag} best ckpt: {best_ckpts[tag]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] {tag}: {e}\")\n",
    "\n",
    "# --- Save comparison CSV ---\n",
    "df = pd.DataFrame(rows).sort_values(\"mAP50-95\", ascending=False)\n",
    "cmp_csv = Path(PROJECT) / \"model_comparison.csv\"\n",
    "cmp_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(cmp_csv, index=False)\n",
    "display(df)\n",
    "print(\"Saved comparison CSV to:\", cmp_csv)\n",
    "\n",
    "# --- Use the globally best model for sample predictions ---\n",
    "if best_ckpts:\n",
    "    best_row  = df.iloc[0]\n",
    "    best_name = best_row[\"model\"]\n",
    "    best_path = best_ckpts[best_name]\n",
    "\n",
    "    print(\"Best model:\", best_name, \"->\", best_path)\n",
    "    model = YOLO(best_path)\n",
    "\n",
    "    # Pick a few validation images\n",
    "    sample_imgs = []\n",
    "    for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "        sample_imgs += glob.glob(str(IM_VAL / \"**\" / ext), recursive=True)\n",
    "    sample_imgs = sample_imgs[:8]\n",
    "    print(\"Predicting on\", len(sample_imgs), \"images...\")\n",
    "\n",
    "    model.predict(\n",
    "        source=sample_imgs,\n",
    "        imgsz=IMG_SIZE,\n",
    "        conf=0.35,\n",
    "        save=True,\n",
    "        project=PROJECT,\n",
    "        name=\"predict_samples\",\n",
    "        device=0,\n",
    "    )\n",
    "\n",
    "    print(\"Predictions saved under:\", Path(PROJECT) / \"predict_samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
